{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Load Dataset\n",
        "data = pd.read_csv(\"dataset/archive/heart_failure_clinical_records_dataset.csv\")\n",
        "print(\"Shape of dataset:\", data.shape)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Data Info and Null Values\n",
        "data.info()\n",
        "print(\"Total null values in dataset:\", data.isnull().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Exploratory Data Analysis (EDA)\n",
        "count_alive = data[data.DEATH_EVENT == 0].shape[0]\n",
        "count_died = data[data.DEATH_EVENT == 1].shape[0]\n",
        "print(f\"Alive: {count_alive}, Died: {count_died}\")\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.pie([count_alive, count_died], labels=[\"Alive\", \"Died\"], explode=[0.1,0], shadow=True, autopct=\"%1.1f%%\")\n",
        "plt.title(\"Death Event Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(data['age'], bins=30, kde=True)\n",
        "plt.title(\"Age Distribution\")\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(12,10))\n",
        "sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Split Dataset\n",
        "X = data.drop('DEATH_EVENT', axis=1)\n",
        "y = data['DEATH_EVENT']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)\n",
        "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Feature Engineering - Interaction Terms (Optional)\n",
        "def add_interactions(X):\n",
        "    X_int = X.copy()\n",
        "    features = X.columns\n",
        "    for i in range(len(features)):\n",
        "        for j in range(i+1, len(features)):\n",
        "            X_int[f\"{features[i]}_x_{features[j]}\"] = X[features[i]] * X[features[j]]\n",
        "    return X_int\n",
        "\n",
        "# Uncomment below to enable interaction features\n",
        "# X_train_mod = add_interactions(X_train)\n",
        "# X_test_mod = add_interactions(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Define Evaluation Function\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    print(\"Accuracy Score:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"Precision Score:\", precision_score(y_true, y_pred))\n",
        "    print(\"Recall Score:\", recall_score(y_true, y_pred))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Logistic Regression Baseline\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "print(\"Logistic Regression Results:\")\n",
        "evaluate_model(y_test, y_pred_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Logistic Regression with StandardScaler\n",
        "lr_pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\n",
        "lr_pipe.fit(X_train, y_train)\n",
        "y_pred_lr_pipe = lr_pipe.predict(X_test)\n",
        "print(\"Logistic Regression with Scaler Results:\")\n",
        "evaluate_model(y_test, y_pred_lr_pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 10: Support Vector Machine with Grid Search\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': [1, 0.1, 0.01, 0.001],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "\n",
        "grid_svc = GridSearchCV(SVC(probability=True), param_grid, refit=True, verbose=1, cv=5)\n",
        "grid_svc.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best SVM parameters:\", grid_svc.best_params_)\n",
        "\n",
        "y_pred_svc = grid_svc.predict(X_test)\n",
        "print(\"SVM Model Results:\")\n",
        "evaluate_model(y_test, y_pred_svc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 11: Decision Tree with Randomized Search\n",
        "param_dist = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': [None, 2, 4, 6, 8],\n",
        "    'min_samples_split': [2, 4, 6, 8],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 0.75, 0.9]\n",
        "}\n",
        "\n",
        "rand_search_dt = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), param_dist, n_iter=20, cv=5, n_jobs=-1, random_state=42)\n",
        "rand_search_dt.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Decision Tree params:\", rand_search_dt.best_params_)\n",
        "\n",
        "y_pred_dt = rand_search_dt.predict(X_test)\n",
        "print(\"Decision Tree Results:\")\n",
        "evaluate_model(y_test, y_pred_dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 12: Random Forest with Randomized Search\n",
        "param_dist_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 2, 4, 6, 8],\n",
        "    'min_samples_leaf': [1, 2, 4, 6],\n",
        "    'max_features': ['auto', 0.5, 0.7],\n",
        "    'min_impurity_decrease': [0.0, 0.01, 0.05]\n",
        "}\n",
        "\n",
        "rand_search_rf = RandomizedSearchCV(RandomForestClassifier(random_state=42), param_dist_rf, n_iter=20, cv=5, n_jobs=-1, random_state=42)\n",
        "rand_search_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Random Forest params:\", rand_search_rf.best_params_)\n",
        "\n",
        "y_pred_rf = rand_search_rf.predict(X_test)\n",
        "print(\"Random Forest Results:\")\n",
        "evaluate_model(y_test, y_pred_rf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 13: XGBoost Classifier\n",
        "from xgboost import XGBClassifier, plot_importance\n",
        "\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=400,\n",
        "    max_depth=4,\n",
        "    learning_rate=0.1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb.fit(X_train, y_train, early_stopping_rounds=10, eval_set=[(X_test, y_test)], verbose=False)\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "print(\"XGBoost Results:\")\n",
        "evaluate_model(y_test, y_pred_xgb)\n",
        "\n",
        "plot_importance(xgb)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 14: Gradient Boosting Classifier\n",
        "gbdt = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=1, random_state=42)\n",
        "gbdt.fit(X_train, y_train)\n",
        "y_pred_gbdt = gbdt.predict(X_test)\n",
        "\n",
        "print(\"Gradient Boosting Results:\")\n",
        "evaluate_model(y_test, y_pred_gbdt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 15: Save Best Model Example (XGBoost)\n",
        "joblib.dump(xgb, 'heart_failure_xgb_model.pkl')\n",
        "print(\"Model saved as 'heart_failure_xgb_model.pkl'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 16: Load & Predict using saved model\n",
        "model = joblib.load('heart_failure_xgb_model.pkl')\n",
        "sample_preds = model.predict(X_test)\n",
        "print(\"Sample predictions:\", sample_preds[:10])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
